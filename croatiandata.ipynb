{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import pearsonr as pearsonr\n",
    "from scipy.stats import skew as skew\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def y_Ao(annotations):\n",
    "    total = 0.0\n",
    "    pairings = [x for x in itertools.combinations(annotations,2)]\n",
    "    for a1,a2 in pairings:\n",
    "        total+=int(a1==a2)\n",
    "    return total / len(pairings)\n",
    "\n",
    "\n",
    "def Datasettime(instancedict):\n",
    "    t =[]\n",
    "    for k in instancedict:\n",
    "        t.extend(instancedict[k].times)\n",
    "    return t\n",
    "    \n",
    "\n",
    "class AnnotatedInstance:\n",
    "    def __init__(self):\n",
    "        self.sentence = ''\n",
    "        self.headword = ''\n",
    "        self.labels = []\n",
    "        self.times = []\n",
    "        \n",
    "    def avg_time(self,threshold=999999999999):\n",
    "        return np.mean(self.times)\n",
    "        \n",
    "    def length(self):\n",
    "        return len(self.sentence.split())\n",
    "    \n",
    "    def Ao(self):\n",
    "        return y_Ao(self.labels)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '-'.join([self.sentence,self.headword,self.rightcontext]+self.labels+[str(x) for x in self.times])\n",
    "    \n",
    "\n",
    "def ReportDataset(instancedict):\n",
    "    alltimes = Datasettime(instancedict)\n",
    "    percentile95 =  np.percentile(alltimes, 95) #right-hand outliers filtered, remove anything above the 95th percentile\n",
    "    alltimes= [x for x in alltimes if x < percentile95]\n",
    "    mean = np.mean(alltimes)\n",
    "    median = np.median(alltimes)\n",
    "    std = np.std(alltimes)\n",
    "    Ao_indiv_list = [instancedict[k].Ao() for k in instancedict.keys()]\n",
    "    Ao_avg = np.mean(Ao_indiv_list)\n",
    "    time_indiv_list =  [instancedict[k].avg_time() for k in instancedict.keys()]\n",
    "    lengths = [instancedict[k].length() for k in instancedict.keys()]\n",
    "    mean_length = np.mean(lengths)\n",
    "    mean_time = np.mean(time_indiv_list)\n",
    "    \n",
    "    corr_len = [mean_length if math.isnan(x)  else x for x in lengths]\n",
    "\n",
    "    print(len(alltimes),len(time_indiv_list),len(lengths),len(Ao_indiv_list))\n",
    "    #return (mean, median, std,percentile95,Ao_avg,pearsonr(Ao_indiv_list,time_indiv_list),pearsonr(lenghts,time_indiv_list)[0])\n",
    "    print(time_indiv_list[:50])\n",
    "    print(lengths[:50])\n",
    "    return (pearsonr(Ao_indiv_list,time_indiv_list),pearsonr(lengths,time_indiv_list))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instances = defaultdict(AnnotatedInstance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'SET' at 0x115b13228>\n",
      "<Element 'SET' at 0x1179061d8>\n",
      "<Element 'SET' at 0x116e6d818>\n",
      "<Element 'SET' at 0x1149a62c8>\n",
      "<Element 'SET' at 0x114ce0048>\n"
     ]
    }
   ],
   "source": [
    "for idx in '1 2 3 4 5'.split():\n",
    "    tree = ET.parse('/Users/hmartine/data/TakeLab-Cro36WSD/annotation_data/annotation_set_'+idx+'.xml')\n",
    "    root = tree.getroot()\n",
    "    print(root)\n",
    "    for instance in root:\n",
    "        ID =  instance.findall(\".//ID\")[0].text\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            timespent = float(instance.findall(\".//TIMESPENT\")[0].text)\n",
    "            if math.isnan(timespent):\n",
    "                print('nan',idx,ID)\n",
    "            sentence =  instance.findall(\".//SENTENCE\")[0].text\n",
    "            senseid = instance.findall(\".//SENSEID\")[0].text\n",
    "            #print(sentence,[x.text for x in instance.findall(\".//TIMESPENT\")])\n",
    "            instances[ID].times.append(timespent)\n",
    "            instances[ID].sentence = sentence\n",
    "            instances[ID].labels.append(senseid) #If there is no annotation it has been discarded, which is also an interesting task\n",
    "        except:\n",
    "            pass# Maybe store under discarded\n",
    "            \n",
    "\n",
    "keptinstances = defaultdict(AnnotatedInstance)\n",
    "for k in instances.keys():\n",
    "    if len(instances[k].labels) >= 2:\n",
    "           keptinstances[k]=instances[k]\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19342 10180 10180 10180\n",
      "[11692.220499999999, 4446.0078000000003, 1996.8035, 5701.8100000000004, 5779.8101500000002, 5070.0089500000004, 6396.0111999999999, 5015.4088000000002, 4032.6071000000002, 4797.0084000000006, 8151.0143000000007, 12285.0216, 13548.623800000001, 3588.0062500000004, 3205.8056500000002, 8439.6147500000006, 16855.829600000001, 9718.8171000000002, 5779.8101500000002, 5592.6098000000002, 7254.0127000000011, 107023.98795000001, 3057.6053499999998, 9609.6168500000003, 3416.4059999999999, 14757.625950000001, 8626.8151500000004, 7862.4138000000003, 3385.20595, 10319.418150000001, 4664.4081500000002, 5545.8096999999998, 6294.6110500000004, 6942.012200000001, 10974.6193, 6505.2114000000001, 3580.2062500000002, 17721.631100000002, 6091.8107, 4110.6072500000009, 6981.0122499999998, 2386.8042000000005, 6021.6105500000003, 16364.428749999999, 1747.2030500000001, 5709.6100000000006, 3907.8069, 3198.0056000000004, 1419.6025500000001, 3439.8060500000001]\n",
      "[69, 21, 63, 30, 10, 18, 71, 58, 36, 30, 25, 47, 44, 62, 33, 20, 20, 61, 19, 35, 23, 14, 27, 42, 24, 22, 17, 26, 21, 21, 31, 41, 12, 56, 81, 9, 26, 24, 38, 8, 46, 19, 25, 36, 27, 28, 25, 69, 24, 14]\n",
      "((-0.15463055605461548, 1.6581162539823172e-55), (0.062217681862047597, 3.3246305030925491e-10))\n"
     ]
    }
   ],
   "source": [
    "print(ReportDataset(keptinstances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Ignore the previous stuff, we are going to try a classifier **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = ET.parse('/Users/hmartine/data/TakeLab-Cro36WSD/datasets/Cro36WSD-M/train/aktivan-a.xml')\n",
    "root = tree.getroot()\n",
    "    print(root)\n",
    "    for instance in root:\n",
    "        ID =  instance.findall(\".//ID\")[0].text\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            timespent = float(instance.findall(\".//TIMESPENT\")[0].text)\n",
    "            if math.isnan(timespent):\n",
    "                print('nan',idx,ID)\n",
    "            sentence =  instance.findall(\".//SENTENCE\")[0].text\n",
    "            senseid = instance.findall(\".//SENSEID\")[0].text\n",
    "            #print(sentence,[x.text for x in instance.findall(\".//TIMESPENT\")])\n",
    "            instances[ID].times.append(timespent)\n",
    "            instances[ID].sentence = sentence\n",
    "            instances[ID].labels.append(senseid) #If there is no annotation it has been discarded, which is also an interesting task\n",
    "        except:\n",
    "            pass# Maybe store under discarded\n",
    "\n",
    "test = ET.parse('/Users/hmartine/data/TakeLab-Cro36WSD/datasets/Cro36WSD-M/test/aktivan-a.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
